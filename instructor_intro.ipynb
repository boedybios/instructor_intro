{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Structure Prompting using Instructor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Instructor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructor is a Python library that helps you get structured, predictable data from language models like GPT-4 and Claude. <br/>\n",
    "It's like giving the LLM a form to fill out instead of letting it respond however it wants.\n",
    "\n",
    "Without Instructor, getting structured data from LLMs can be challenging:\n",
    "- Unpredictable outputs: LLMs might format responses differently each time\n",
    "- Format errors: Getting JSON or specific data structures can be error-prone\n",
    "- Validation headaches: Checking if the response matches what you need\n",
    "\n",
    "Instructor solves these problems by:\n",
    "- Defining exactly what data you want using Python classes\n",
    "- Making sure the LLM returns data in that structure\n",
    "- Validating the output and automatically fixing issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the LLM with Instructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI, AzureOpenAI\n",
    "import instructor\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# client = instructor.from_openai(OpenAI())\n",
    "client = instructor.from_openai(AzureOpenAI())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study: Simple extraction from a text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"John is a 30 years old software engineer. \n",
    "He was born in Cicago and currently resides in New York.\n",
    "He has houses at 123 Main St, Springfield, IL 62704 and 456 Oak Ave, Chicago, IL 60601.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the expected response structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    name: str\n",
    "    age: int = Field(description=\"The user's age in years\", gt=0, lt=120)\n",
    "    city: str = Field(description=\"The city where the user lives\")\n",
    "    occupation: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a personal data extraction engine which capable to extract several personal details from a given text.\"\n",
    "user_prompt = f\"Extract a person from: {text}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract structured data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "person = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    response_model=Person,\n",
    "    temperature=0.0,\n",
    "    max_retries=5,\n",
    "    stream=False,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_prompt,\n",
    "        },\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: John\n",
      "Age: 30\n",
      "City: New York\n",
      "Occupation: software engineer\n"
     ]
    }
   ],
   "source": [
    "print(f\"Name: {person.name}\")\n",
    "print(f\"Age: {person.age}\")\n",
    "print(f\"City: {person.city}\")\n",
    "print(f\"Occupation: {person.occupation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's wrap it as a proper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_person_data(text: str) -> Person:\n",
    "    system_prompt = \"You are a personal data extraction engine which capable to extract several personal details from a given text.\"\n",
    "    user_prompt = f\"Extract a person from: {text}\"\n",
    "\n",
    "    return client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        response_model=Person,\n",
    "        temperature=0.0,\n",
    "        max_retries=5,\n",
    "        stream=False,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt,\n",
    "            },\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: John\n",
      "Age: 30\n",
      "City: New York\n",
      "Occupation: software engineer\n"
     ]
    }
   ],
   "source": [
    "person = extract_person_data(text)\n",
    "\n",
    "print(f\"Name: {person.name}\")\n",
    "print(f\"Age: {person.age}\")\n",
    "print(f\"City: {person.city}\")\n",
    "print(f\"Occupation: {person.occupation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study: A more complex extraction from a text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a more complex response structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Address(BaseModel):\n",
    "    street: str\n",
    "    city: str\n",
    "    state: str\n",
    "    zip_code: str\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    name: str\n",
    "    age: int = Field(description=\"The user's age in years\", gt=0, lt=120)\n",
    "    city: str = Field(description=\"The city where the user lives\")\n",
    "    occupation: str\n",
    "    addresses: list[Address] = Field(description=\"The addresses of the user\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No changes in both prompt and the extraction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "person = extract_person_data(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New structured response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: John\n",
      "Age: 30\n",
      "City: New York\n",
      "Occupation: software engineer\n",
      "Addresses: [Address(street='123 Main St', city='Springfield', state='IL', zip_code='62704'), Address(street='456 Oak Ave', city='Chicago', state='IL', zip_code='60601')]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Name: {person.name}\")\n",
    "print(f\"Age: {person.age}\")\n",
    "print(f\"City: {person.city}\")\n",
    "print(f\"Occupation: {person.occupation}\")\n",
    "print(f\"Addresses: {person.addresses}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Address:\n",
      "    \t Street: 123 Main St\n",
      "    \t City: Springfield\n",
      "    \t State: IL\n",
      "    \t ZIP Code: 62704\n",
      "Address:\n",
      "    \t Street: 456 Oak Ave\n",
      "    \t City: Chicago\n",
      "    \t State: IL\n",
      "    \t ZIP Code: 60601\n"
     ]
    }
   ],
   "source": [
    "for address in person.addresses:\n",
    "    print(\n",
    "        f\"\"\"Address:\n",
    "    \\t Street: {address.street}\n",
    "    \\t City: {address.city}\n",
    "    \\t State: {address.state}\n",
    "    \\t ZIP Code: {address.zip_code}\"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study: URL extraction from a markdown document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"document.md\", \"r\") as file:\n",
    "    input_document = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the response structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, HttpUrl\n",
    "\n",
    "\n",
    "class ExtractedURL(BaseModel):\n",
    "    url: list[HttpUrl] = Field(\n",
    "        description=\"List of extracted URLs from a given document\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a URL extraction engine.\"\n",
    "user_prompt = f\"Extract list of URLs from this document: {input_document}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_url = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    response_model=ExtractedURL,\n",
    "    temperature=0.0,\n",
    "    max_retries=5,\n",
    "    stream=False,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_prompt,\n",
    "        },\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ai.google/research\n",
      "https://azure.microsoft.com/\n",
      "https://twitter.com/technews\n",
      "https://linkedin.com/tech\n",
      "https://instagram.com/techtrends\n",
      "https://github.com/\n",
      "https://www.codecademy.com/\n",
      "https://stackoverflow.com/\n",
      "https://techconference2024.com/\n",
      "https://aisummit.global/\n",
      "https://webdevconf.org/\n",
      "https://techportal.com/\n",
      "https://twitter.com/techportal\n"
     ]
    }
   ],
   "source": [
    "for url in extracted_url.url:\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study: Single Label Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the response structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "class ClassificationResponse(BaseModel):\n",
    "    \"\"\"\n",
    "    A few-shot example of text classification:\n",
    "\n",
    "    Examples:\n",
    "    - \"Buy cheap watches now!\": SPAM\n",
    "    - \"Meeting at 3 PM in the conference room\": NOT_SPAM\n",
    "    - \"You've won a free iPhone! Click here\": SPAM\n",
    "    - \"Can you pick up some milk on your way home?\": NOT_SPAM\n",
    "    - \"Increase your followers by 10000 overnight!\": SPAM\n",
    "    \"\"\"\n",
    "\n",
    "    chain_of_thought: str = Field(\n",
    "        description=\"The chain of thought that led to the prediction.\",\n",
    "    )\n",
    "    label: Literal[\"SPAM\", \"NOT_SPAM\"] = Field(\n",
    "        description=\"The predicted class label.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the classification function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(input_text: str) -> ClassificationResponse:\n",
    "    system_prompt = \"You are a text classification engine which capable to classify a given text as SPAM or NOT_SPAM\"\n",
    "    user_prompt = f\"Classify the following text: <text>{input_text}</text>\"\n",
    "\n",
    "    return client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        response_model=ClassificationResponse,\n",
    "        temperature=0.0,\n",
    "        max_retries=5,\n",
    "        stream=False,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt,\n",
    "            },\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Hey Jason! You're awesome, Predicted Label: NOT_SPAM\n",
      "Chain of thought: The text is a friendly message expressing appreciation towards someone named Jason. It does not contain any promotional content, offers, or requests that are typical of spam messages. Therefore, it is classified as NOT_SPAM.\n",
      "========================================================================================================================\n",
      "Text: I am a nigerian prince and I need your help., Predicted Label: SPAM\n",
      "Chain of thought: The text claims to be from a 'Nigerian prince' asking for help, which is a common trope in spam messages that often involve scams. This type of message typically aims to deceive the recipient into providing personal information or money. Therefore, it is classified as SPAM.\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for text in [\n",
    "    \"Hey Jason! You're awesome\",\n",
    "    \"I am a nigerian prince and I need your help.\",\n",
    "]:\n",
    "    prediction = classify(text)\n",
    "    print(f\"Text: {text}, Predicted Label: {prediction.label}\")\n",
    "    print(f\"Chain of thought: {prediction.chain_of_thought}\")\n",
    "    print(\"=\" * 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study: Multi Label Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the response structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "class MultiClassPrediction(BaseModel):\n",
    "    \"\"\"\n",
    "    Class for a multi-class label prediction.\n",
    "\n",
    "    Examples:\n",
    "    - \"My account is locked\": [\"TECH_ISSUE\"]\n",
    "    - \"I can't access my billing info\": [\"TECH_ISSUE\", \"BILLING\"]\n",
    "    - \"When do you close for holidays?\": [\"GENERAL_QUERY\"]\n",
    "    - \"My payment didn't go through and now I can't log in\": [\"BILLING\", \"TECH_ISSUE\"]\n",
    "    \"\"\"\n",
    "\n",
    "    chain_of_thought: str = Field(\n",
    "        description=\"The chain of thought that led to the prediction.\",\n",
    "    )\n",
    "\n",
    "    class_labels: List[Literal[\"TECH_ISSUE\", \"BILLING\", \"GENERAL_QUERY\"]] = Field(\n",
    "        description=\"The predicted class labels for the support ticket.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the classification function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_classify(input_text: str) -> MultiClassPrediction:\n",
    "    user_prompt = (\n",
    "        f\"Classify the following support ticket: <ticket>{input_text}</ticket>\"\n",
    "    )\n",
    "\n",
    "    return client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        response_model=MultiClassPrediction,\n",
    "        temperature=0.0,\n",
    "        max_retries=5,\n",
    "        stream=False,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt,\n",
    "            },\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticket: My account is locked and I can't access my billing info.\n",
      "Predicted Labels: ['TECH_ISSUE', 'BILLING']\n",
      "Chain of thought: The user mentions that their account is locked, which indicates a technical issue. Additionally, they state that they cannot access their billing information, which relates to billing concerns. Therefore, the ticket involves both a technical issue and a billing issue.\n"
     ]
    }
   ],
   "source": [
    "ticket = \"My account is locked and I can't access my billing info.\"\n",
    "prediction = multi_classify(ticket)\n",
    "\n",
    "print(f\"Ticket: {ticket}\")\n",
    "print(f\"Predicted Labels: {prediction.class_labels}\")\n",
    "print(f\"Chain of thought: {prediction.chain_of_thought}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "instructor312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
